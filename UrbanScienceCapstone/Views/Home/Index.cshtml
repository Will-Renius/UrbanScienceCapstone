<style>
    .center {
        text-align: center;
        margin: auto;
        width: 100%;
        height:90%;
        transform:translateY(10%)
    }
    body {
       background-color: #f0f0f0;
    }
    #img_logo{
        max-width:300px;
    }
    #searchbox {
        max-width: 800px;
        margin: auto;
        margin-top: 10px;
    }
</style>
<body>


    <div class="center" style="text-align:center;">
        @{
            ViewBag.Title = "Virtual Dealership Adviser";
        }
        
        
        <img id="img_logo" alt="logo" src="~/images/UsLogoTransparantBlack.png" />
        @* <h1> Virtual Dealership Adviser</h1>*@
       @* <h1>Welcome to the @ViewBag.dealer_name Virtual Dealership Adviser!</h1>*@
       @* <h2>Hello @ViewBag.first_name @ViewBag.last_name</h2>*@
        
        @model UrbanScienceCapstone.Models.Search
        @using (Html.BeginForm("KPI", "Home", FormMethod.Post))
        {
            <div class="input-group">


                @Html.TextBoxFor(model => model.search, new { @id = "searchbox", @class = "form-control" })
                @Html.ValidationMessageFor(model => model.search)
                @*<button type="button" id="startBtn" class="btn btn-success input-group-addon">
                    <i class="fa fa-microphone" aria-hidden="true"></i>
                </button>
                <button type="button" id="stopBtn" class="btn btn-danger input-group-addon">
                    <i class="fa fa-microphone-slash" aria-hidden="true"></i>
                </button>*@
               @* <span class="input-group-addon">.00</span>*@

            </div>
            <div class="search-buttons" style="margin-top:15px">     

                <button type="button" id="startBtn" class="btn btn-success">
                    <i class="fa fa-microphone" aria-hidden="true"></i>
                </button>
                <button type="button" id="stopBtn" class="btn btn-danger">
                    <i class="fa fa-microphone-slash" aria-hidden="true"></i>
                </button>
                <button type="submit" class="btn btn-success">Search</button>
            </div>
        }

       
        <br />
        <div style="display:none;">


            <select id="formatOptions">
                <option value="Simple" selected="selected">Simple Result</option>
                <option value="Detailed">Detailed Result</option>
            </select>
            <br />

            <textarea id="phraseDiv" style="width:500px;height:200px"></textarea>
            <br />
            Status: <span id="statusDiv"></span>

        </div>


    </div>
</body>



                

@section Scripts {
    <!-- The SDK has a dependency on requirejs (http://requirejs.org/). -->
    <script src="//cdnjs.cloudflare.com/ajax/libs/require.js/2.3.3/require.min.js"></script>
    <script>
        // Special handling to let the sample work when loaded directly from file system.
        if (window.location.protocol == "file:") {
            document.write('\<script src="http://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.3/require.min.js">\<\/script>');
        }
    </script>
    <!-- SDK REFERENCE -->
    <script src="~/SpeechToText-WebSockets-Javascript-master/distrib/speech.browser.sdk-min.js"></script>
    <!-- SDK USAGE -->
    <script>
        // On doument load resolve the SDK dependecy
        function Initialize(onComplete) {
            require(["Speech.Browser.Sdk"], function (SDK) {
                onComplete(SDK);
            });
        }

        // Setup the recongizer
        function RecognizerSetup(SDK, recognitionMode, language, format, subscriptionKey) {
            var recognizerConfig = new SDK.RecognizerConfig(
                new SDK.SpeechConfig(
                    new SDK.Context(
                        new SDK.OS(navigator.userAgent, "Browser", null),
                        new SDK.Device("SpeechSample", "SpeechSample", "1.0.00000"))),
                recognitionMode, // SDK.RecognitionMode.Interactive  (Options - Interactive/Conversation/Dictation>)
                language, // Supported laguages are specific to each recognition mode. Refer to docs.
                format); // SDK.SpeechResultFormat.Simple (Options - Simple/Detailed)

            // Alternatively use SDK.CognitiveTokenAuthentication(fetchCallback, fetchOnExpiryCallback) for token auth
            var authentication = new SDK.CognitiveSubscriptionKeyAuthentication(subscriptionKey);

            return SDK.CreateRecognizer(recognizerConfig, authentication);
        }

        // Start the recognition
        function RecognizerStart(SDK, recognizer) {
            recognizer.Recognize((event) => {
                /*
                 Alternative syntax for typescript devs.
                 if (event instanceof SDK.RecognitionTriggeredEvent)
                */
                switch (event.Name) {
                    case "RecognitionTriggeredEvent":
                        UpdateStatus("Initializing");
                        break;
                    case "ListeningStartedEvent":
                        UpdateStatus("Listening");
                        break;
                    case "RecognitionStartedEvent":
                        UpdateStatus("Listening_Recognizing");
                        break;
                    case "SpeechStartDetectedEvent":
                        UpdateStatus("Listening_DetectedSpeech_Recognizing");
                        console.log(JSON.stringify(event.Result)); // check console for other information in result
                        break;
                    case "SpeechHypothesisEvent":
                        UpdateRecognizedHypothesis(event.Result.Text);
                        console.log(JSON.stringify(event.Result)); // check console for other information in result
                        break;
                    case "SpeechEndDetectedEvent":
                        OnSpeechEndDetected();
                        UpdateStatus("Processing_Adding_Final_Touches");
                        console.log(JSON.stringify(event.Result)); // check console for other information in result
                        break;
                    case "SpeechSimplePhraseEvent":
                        UpdateRecognizedPhrase(JSON.stringify(event.Result, null, 3));
                        break;
                    case "SpeechDetailedPhraseEvent":
                        UpdateRecognizedPhrase(JSON.stringify(event.Result, null, 3));
                        break;
                    case "RecognitionEndedEvent":
                        OnComplete();
                        UpdateStatus("Idle");
                        console.log(JSON.stringify(event)); // Debug information
                        break;
                }
            })
                .On(() => {
                    // The request succeeded. Nothing to do here.
                },
                (error) => {
                    console.error(error);
                });
        }

        // Stop the Recognition.
        function RecognizerStop(SDK, recognizer) {
            // recognizer.AudioSource.Detach(audioNodeId) can be also used here. (audioNodeId is part of ListeningStartedEvent)
            recognizer.AudioSource.TurnOff();
        }
    </script>
    <!-- Browser Hooks -->
    <script>
        var startBtn, stopBtn, hypothesisDiv, phraseDiv, statusDiv, key, formatOptions;
        var SDK;
        var recognizer;
        var previousSubscriptionKey;

        document.addEventListener("DOMContentLoaded", function () {
            createBtn = document.getElementById("createBtn");
            startBtn = document.getElementById("startBtn");
            stopBtn = document.getElementById("stopBtn");
            phraseDiv = document.getElementById("phraseDiv");
            hypothesisDiv = document.getElementById("searchbox");
            statusDiv = document.getElementById("statusDiv");
            //new: 66a26f67d25047f58c82aeb821a0533e
            //old: 12db281210d349b8beb823e44e49543b
            key = "66a26f67d25047f58c82aeb821a0533e";

            formatOptions = document.getElementById("formatOptions");

            

            formatOptions.addEventListener("change", function () {
                Setup();
            });

            startBtn.addEventListener("click", function () {
                if (!recognizer || previousSubscriptionKey != key) {
                    previousSubscriptionKey = key;
                    Setup();
                }

                hypothesisDiv.value = "";
                phraseDiv.innerHTML = "";
                RecognizerStart(SDK, recognizer);
                startBtn.disabled = true;
                stopBtn.disabled = false;
            });

            stopBtn.addEventListener("click", function () {
                RecognizerStop(SDK);
                startBtn.disabled = false;
                stopBtn.disabled = true;
            });

            Initialize(function (speechSdk) {
                SDK = speechSdk;
                startBtn.disabled = false;
            });
        });

        function Setup() {
            recognizer = RecognizerSetup(SDK, SDK.RecognitionMode.Interactive, "en-US", SDK.SpeechResultFormat[formatOptions.value], key);
        }

        function UpdateStatus(status) {
            statusDiv.innerHTML = status;
        }

        function UpdateRecognizedHypothesis(text) {
            hypothesisDiv.value = text;
        }

        function OnSpeechEndDetected() {
            stopBtn.disabled = true;
        }

        function UpdateRecognizedPhrase(json) {
            phraseDiv.innerHTML = json;
        }

        function OnComplete() {
            startBtn.disabled = false;
            stopBtn.disabled = true;
        }
    </script>
}
